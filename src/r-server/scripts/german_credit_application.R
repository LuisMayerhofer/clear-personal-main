############################################
### German Credit Application
############################################
# Get current working directory (should be project root)
current_dir <- getwd()

# Create results directory if it doesn't exist
results_dir <- file.path(current_dir, "src", "r-server", "results")


#--- Setup ----
# To run MOC
# devtools::install("../src/r-server/counterfactuals/")
library("counterfactuals")
library("mosmafs")


####
url <- "https://cran.r-project.org/src/contrib/Archive/mosmafs/mosmafs_0.1.2.tar.gz"
pkgFile <- "mosmafs_0.1.2.tar.gz"
download.file(url = url, destfile = pkgFile)

# Expand the zip file using whatever system functions are preferred

# look at the DESCRIPTION file in the expanded package directory

# Install dependencies list in the DESCRIPTION file

#install.packages(c("ada", "ipred", "evd"))

# Install package
# install.packages(pkgs=pkgFile, type="source", repos=NULL)

# Delete package tarball
unlink(pkgFile)

####

library("mlr")
library("mlrCPO")
library("ggplot2")
library("iml")

best.params = readRDS(file.path(
  current_dir,
  "src",
  "r-server",
  "saved_objects",
  "best_configs.rds"
)) # generated by irace in folder appendix_irace
USE_TRAINED_MODEL = TRUE
PARALLEL = TRUE

# Helper function for visible logging
log_message <- function(message, data = NULL) {
  cat("\n", rep("=", 80), "\n", sep = "")
  cat(format(Sys.time(), "%Y-%m-%d %H:%M:%S"), " - ", message, "\n")
  if (!is.null(data)) {
    cat("Data:\n")
    print(data)
  }
  cat(rep("=", 80), "\n\n", sep = "")
}


###---- Get data ----
# Read command line arguments
args <- commandArgs(trailingOnly = TRUE)
input_file <- args[1]
locked_file <- args[2]

# Read the input data
x.interest <- read.csv(input_file, stringsAsFactors = TRUE)
# Normalize column names to match training data
names(x.interest) <- tolower(names(x.interest))
names(x.interest) <- gsub(" ", "", names(x.interest)) # Remove spaces
cat('x.interest after reading and normalization:\n')
print(x.interest)
str(x.interest)

# Ensure x.interest has the same structure as verification data
# Set factor levels to match verification data BEFORE job mapping
x.interest$sex <- factor(x.interest$sex, levels = c("female", "male"))
x.interest$housing <- factor(
  x.interest$housing,
  levels = c("free", "own", "rent")
)
x.interest$checking.account <- factor(
  x.interest$checking.account,
  levels = c("little", "moderate", "rich")
)
x.interest$purpose <- factor(
  x.interest$purpose,
  levels = c("others", "car", "furniture", "radio/TV")
)
x.interest$saving.accounts <- factor(
  x.interest$saving.accounts,
  levels = c("little", "moderate", "rich")
)

# Initialize risk column (will be set after prediction)
if (!"risk" %in% names(x.interest)) {
  x.interest$risk <- NA
}
x.interest$risk <- factor(x.interest$risk, levels = c("bad", "good"))

# Read the locked features
locked_lines <- readLines(locked_file)
if (length(locked_lines) == 0 || locked_lines == "") {
  locked_features <- character(0)
} else {
  locked_features <- strsplit(locked_lines, ",")[[1]]
}

# Map Job string to numeric as required by the model (only if it's not already numeric)
if (!is.numeric(x.interest$job)) {
  job_map <- c(
    "unskilled and non-resident" = 0,
    "unskilled and resident" = 1,
    "skilled" = 2,
    "highly skilled" = 3
  )
  # Map job to integer (not numeric)
  x.interest$job <- as.integer(job_map[as.character(x.interest$job)])
}


# Read the training data
credit = read.csv(
  file.path(current_dir, "src", "r-server", "data", "german_credit_data.csv"),
  row.names = 1,
  stringsAsFactors = TRUE
)
# names(credit)
# omit rows with NA entries
credit = na.omit(credit)
# join groups with small frequencies
levels(credit$Purpose) = c(
  "others",
  "car",
  "others",
  "others",
  "furniture",
  "radio/TV",
  "others",
  "others"
)
levels(credit$Saving.accounts) = c("little", "moderate", "rich", "rich")
# Colnames to lower
names(credit) = tolower(names(credit))
# Drop levels
credit = droplevels.data.frame(credit)

# Debug: Check structure of both datasets
cat('\nTraining data structure:\n')
str(credit)
cat('\nUser data structure after factor adjustment:\n')
str(x.interest)

###---- Train model ----
if (USE_TRAINED_MODEL) {
  credit.model = readRDS(file.path(
    current_dir,
    "src",
    "r-server",
    "models",
    "model_svm.rds"
  ))
} else {
  credit.task = makeClassifTask(id = "credit", data = credit, target = "risk")
  lrn = makeLearner("classif.svm", predict.type = "prob")
  credit.lrn = cpoScale() %>>% cpoDummyEncode() %>>% lrn
  param.set = pSS(
    cost:numeric[0.01, 1]
  )

  TUNEITERS = 100L
  RESAMPLING = cv5

  if (PARALLEL) {
    parallelMap::parallelStartSocket(
      parallel::detectCores(),
      level = "mlr.tuneParams"
    )
  }

  ctrl = makeTuneControlRandom(maxit = TUNEITERS * length(param.set$pars))
  lrn.tuning = makeTuneWrapper(
    lrn,
    RESAMPLING,
    list(mlr::acc),
    param.set,
    ctrl,
    show.info = FALSE
  )
  res = tuneParams(
    lrn,
    credit.task,
    RESAMPLING,
    par.set = param.set,
    control = ctrl,
    show.info = FALSE
  )
  performance = resample(
    lrn.tuning,
    credit.task,
    RESAMPLING,
    list(mlr::acc)
  )$aggr

  if (PARALLEL) {
    parallelMap::parallelStop()
  }
  credit.lrn = setHyperPars2(credit.lrn, res$x)
  credit.model = mlr::train(credit.lrn, credit.task) # use mlr:: in case caret is loaded somewhere
}

pred = Predictor$new(model = credit.model, data = credit, class = "good")

# Generate predictions for training data and create extended version
training_predictions <- pred$predict(credit)
credit_extended <- credit
credit_extended$pred <- training_predictions$good

# Save extended training data with predictions
write.csv(
  credit_extended,
  file.path(
    current_dir,
    "src",
    "r-server",
    "data",
    "german_credit_data_with_predictions.csv"
  ),
  row.names = TRUE
)

log_message("Extended training data with predictions saved")

# fit conditionals
ctr = partykit::ctree_control(maxdepth = 5L)
set.seed(1234)
cond = fit_conditionals(pred$data$get.x(), ctrl = ctr)


###---- Compute counterfactuals ----
user_prediction <- pred$predict(x.interest)
cat('User prediction:\n')
print(user_prediction)

# Add the risk prediction and probability to x.interest
x.interest$risk <- ifelse(user_prediction$good > 0.5, "good", "bad")
x.interest$pred <- user_prediction$good

set.seed(1000)

# Use locked features if provided
if (length(locked_features) > 0) {
  fixed.features = locked_features
} else {
  fixed.features = NULL
}

# Add logging for counterfactual generation
log_message("Starting counterfactual generation")
log_message("Input features", names(x.interest))
log_message("Fixed features", fixed.features)

system.time({
  credit.cf = Counterfactuals$new(
    predictor = pred,
    x.interest = x.interest,
    conditionals = cond,
    target = c(0.5, 1),
    epsilon = 0,
    generations = list(
      mosmafs::mosmafsTermStagnationHV(10),
      mosmafs::mosmafsTermGenerations(200)
    ),
    mu = best.params$mu,
    p.mut = best.params$p.mut,
    p.rec = best.params$p.rec,
    p.mut.gen = best.params$p.mut.gen,
    p.mut.use.orig = best.params$p.mut.use.orig,
    p.rec.gen = best.params$p.rec.gen,
    initialization = "icecurve",
    p.rec.use.orig = best.params$p.rec.use.orig,
    fixed.features = fixed.features
  )
})

# Log results
log_message("Counterfactual generation completed")
log_message(
  "Number of counterfactuals generated",
  nrow(credit.cf$results$counterfactuals)
)
log_message(
  "Number of counterfactuals meeting target",
  sum(credit.cf$results$counterfactuals$dist.target == 0)
)

# Get relative frequency of feature changes
freq <- credit.cf$get_frequency()
log_message("Feature change frequencies", freq)

# Create timestamp for unique filename
timestamp <- format(Sys.time(), "%Y%m%d_%H%M%S")
results_filename <- paste0("results_", timestamp, ".csv")

# Save results to CSV
write.csv(
  credit.cf$results$counterfactuals,
  file.path(results_dir, results_filename),
  row.names = FALSE
)

# Also save results with standard name for processing pipeline
write.csv(
  credit.cf$results$counterfactuals,
  file.path(results_dir, "results.csv"),
  row.names = FALSE
)

# Save user data to CSV
user_filename <- paste0("user_", timestamp, ".csv")
write.csv(x.interest, file.path(results_dir, user_filename), row.names = FALSE)

# Also save user data with standard name for processing pipeline
write.csv(x.interest, file.path(results_dir, "user.csv"), row.names = FALSE)

# Write detailed log
log_entry <- paste(
  "Generated results at:",
  Sys.time(),
  "\nCounterfactuals file:",
  results_filename,
  "\nUser data file:",
  user_filename,
  "\nNumber of counterfactuals:",
  nrow(credit.cf$results$counterfactuals),
  "\nUser prediction probability:",
  round(user_prediction$good, 4),
  "\nUser predicted risk:",
  x.interest$risk,
  "\nFeatures changed:",
  paste(names(freq), collapse = ", "),
  "\nChange frequencies:",
  paste(freq, collapse = ", "),
  "\n---\n"
)

write(log_entry, file.path(results_dir, "generation_log.txt"), append = TRUE)
